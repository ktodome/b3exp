{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 有意性の推定"
      ],
      "metadata": {
        "id": "ayrJ-wZmPg0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "測定された散乱事象数は測定に対してどの程度一致したでしょうか？ラザフォード散乱があることを再発見するためには、なるべく大角度での散乱事象を観測することが望ましいです。測定回数は散乱事象を観測したと宣言するのに十分でしょうか。\n",
        "\n",
        "信号事象の有意性を議論するためには、観測された事象数Nが「背景事象数bと誤差σの仮定のみで観測される確率」を計算します。**背景事象だけで実際に観測された事象数が説明できてしまう確率が十分小さい**ことを示すことで、信号が有意であることを示します。推定信号事象数sが事前にわかっている際は、N=s+bとすることで事前に推定値を計算することもできます。\n",
        "\n",
        "ここでは確率分布が正規分布であると仮定して、有意性を\n",
        "\n",
        "$$\n",
        "Z=\\frac{n-b}{\\sqrt{b+\\sigma^2}}\n",
        "$$\n",
        "\n",
        "を用いて計算します[<sup>1</sup>](#id_01)。sを用いる場合は\n",
        "\n",
        "$$\n",
        "Z=\\frac{s}{\\sqrt{b+\\sigma^2}}\n",
        "$$\n",
        "とすればおおよその値を計算できます。\n",
        "\n",
        "<span id=\"id_01\">[1]確率分布がbを中心とした幅$b+\\sigma^2$のガウシアンと仮定すると得られる。背景事象が十分にない場合はガウシアンでなくポアソン分布を仮定する必要があり、より複雑な式で計算する必要がある。</span>"
      ],
      "metadata": {
        "id": "sSdS0tMpPo9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.0. 初期設定・測定データの確認"
      ],
      "metadata": {
        "id": "zJMONfSQZ6fE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは3.0.1.でこの有意性の式を含めた関数を定義します。また、有意性は1σ, 2σなどと表しますが、これを具体的な確率に計算しなおす関数も定義します。前回の情報は3.0.3.を編集することで取り込めますし、このノートブックから必要なセルを前回のノートブックにコピーしてもよいです。"
      ],
      "metadata": {
        "id": "_OTMSKxPZ7TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.0.1. 必要設定の読み込み\n",
        "\n",
        "#スクリプト実行に必要なパッケージ。\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit,minimize\n",
        "from scipy.stats import poisson,norm\n",
        "from scipy import integrate\n",
        "\n",
        "#用いる関数を定義\n",
        "def sig(x, a, m, s):#ガウシアン\n",
        "    if a<0 or s<0:\n",
        "        return 1e99\n",
        "    return a*np.exp(-0.5*(x-m)**2/s**2)\n",
        "\n",
        "def bg(x, b, beta):#exponential\n",
        "    return b*np.exp(-x/beta)\n",
        "\n",
        "def sigFull(x, a, m, s, b, beta):\n",
        "    return sig(x,a,m,s)+bg(x,b,beta)\n",
        "\n",
        "\n",
        "def lin(x,a,b):\n",
        "    return a*x+b\n",
        "\n",
        "def dlin(x,a,b,dx,da,db):#直線フィッティングの誤差導出用関数\n",
        "    dy=(x*da)**2\n",
        "    dy+=(dx*a)**2\n",
        "    dy+=db**2\n",
        "    dy=np.sqrt(dy)\n",
        "    #print(\"{:10.4f}, {:10.4f}, {:10.4f}\".format((x*da),dx*a,db))\n",
        "    return dy\n",
        "def pathToTime(path):\n",
        "    time_format='\"%Y-%m-%d\" \"%H:%M:%S\"'\n",
        "    temp = np.genfromtxt(path, skip_header=1025,skip_footer=1,dtype=str)\n",
        "    start_text=temp[0]+' '+temp[1]\n",
        "    start_time=datetime.datetime.strptime(start_text, time_format)\n",
        "    end_text=temp[2]+' '+temp[3]\n",
        "    end_time=datetime.datetime.strptime(end_text, time_format)\n",
        "    Time=(end_time-start_time).seconds\n",
        "    return Time\n",
        "\n",
        "def significance(n, b, sigma): #有意性を返す式\n",
        "    return (n-b)/np.sqrt(b+sigma**2)\n",
        "\n",
        "def prob(Z):#有意性を「観測した事象より大きく予想から外れる確率」に解釈しなおす式\n",
        "    return 1-(norm.cdf(Z)-norm.cdf(-Z))\n",
        "\n",
        "def rebin(x,y,ndiv=3):\n",
        "    bins = len(x)-1\n",
        "    # ndiv\n",
        "    print(len(x),x[-1],ndiv,bins%ndiv)\n",
        "    if bins%ndiv != 0:\n",
        "      return rebin(x[:-1],y[:-1],ndiv)\n",
        "    bins_new = int(bins/ndiv)\n",
        "    print(bins_new)\n",
        "    dx=x[1]-x[0]\n",
        "    x_new = np.linspace(x[0],x[-1], bins_new+1)\n",
        "    y_new = np.array([np.sum(y[i*ndiv:(i+1)*ndiv]) for i in range(bins_new+1)])\n",
        "    print(len(x_new),x_new[-1])\n",
        "    return x_new, y_new\n",
        "\n",
        "#使用例\n",
        "n=110\n",
        "dn=4.3\n",
        "b=50\n",
        "sigma=np.sqrt(dn**2+b)\n",
        "print(\"背景事象数 {:.2f} +/- {:.2f} と推測されるとき、{:d}回より大きく予想が外れる確率{:.2f}σ={:.2e}%\".format(b,sigma,n,significance(n,b,sigma),prob(significance(n,b,sigma))*100))\n",
        "print(\"信号事象発見に必要な有意性5σ={:.2e}%\".format(prob(5)*100))\n",
        "print(\"3σ={:.2e}%\".format(prob(3)*100))\n",
        "print(\"2σ={:.2e}%\".format(prob(2)*100))\n",
        "print(\"1σ={:.2e}%\".format(prob(1)*100))"
      ],
      "metadata": {
        "id": "hALijMvCIlMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.0.2. Googleドライブのマウント(オプション)\n",
        "\n",
        "#実験データなど、Googleドライブにあるファイルにアクセスしたい場合に実行する。自分のアカウントで要認証。ダミーデータで取り組む場合は実行不要\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#ファイルを格納するディレクトリを指定、要編集\n",
        "basePath='/content/drive/MyDrive/temp/b3exp/'"
      ],
      "metadata": {
        "id": "u1PwaTPOIvG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.0.3. 必要な情報の引継ぎ\n",
        "\n",
        "#パスと名前を書き換える\n",
        "#パルス情報\n",
        "pulse_file_list=[]\n",
        "pulse_file_list.append(['pulse2p4.csv',2.4])\n",
        "pulse_file_list.append(['pulse2p2.csv',2.2])\n",
        "pulse_file_list.append(['pulse2p0.csv',2.0])\n",
        "pulse_file_list.append(['pulse1p8.csv',1.8])\n",
        "pulse_file_list.append(['pulse1p6.csv',1.6])\n",
        "pulse_file_list.append(['pulse1p4.csv',1.4])\n",
        "#強度測定\n",
        "calib_file='60sec0degNoTarget.csv'\n",
        "#厚さ測定\n",
        "Aldeg0 = np.genfromtxt(basePath+'60sec0degAl.csv', skip_footer=6)\n",
        "Audeg0 = np.genfromtxt(basePath+'Au.csv', skip_footer=6)\n",
        "#測定パラメタ\n",
        "theta=20\n",
        "tmes=300#sec, 測定時間\n",
        "\n",
        "#以下書き換え不要\n",
        "\n",
        "pulse_list=np.empty((0,1024),int)\n",
        "hight=[]\n",
        "for file_i in pulse_file_list:#入力したデータ数分繰り返し\n",
        "    y=np.genfromtxt(basePath+file_i[0], skip_footer=6)#1ヒストグラム取り出し\n",
        "    y=[y]\n",
        "    pulse_list=np.append(pulse_list,y,axis=0)\n",
        "    hight=np.append(hight,file_i[1])\n",
        "ch = []\n",
        "dch = []\n",
        "x=np.arange(0,1024)#x軸\n",
        "dA=10\n",
        "for hight_i,pulse_i in zip(hight,pulse_list):#入力したデータ数分繰り返し\n",
        "    y=pulse_i\n",
        "    dy=np.where(y > 0, np.sqrt(y), 1.0)#誤差は統計誤差の√nのみ,nが0なら0\n",
        "    par_gaus, cov_gaus = curve_fit(sig, x, y, p0=(np.max(y), np.argmax(y), dA),sigma=dy)#適切な初期値を与えてフィッティング\n",
        "    perr_gaus = np.sqrt(np.diag(cov_gaus))#分散共分散行列の対角成分取り出し=分散の取り出し\n",
        "    #結果を記録\n",
        "    ch=np.append(ch,float(par_gaus[1]))\n",
        "    dch=np.append(dch,float(perr_gaus[1]))\n",
        "par_line, cov_line = curve_fit(lin, ch, hight, sigma=dch)#f(ch+/-dch)=Eを直線(lin)でフィッティング\n",
        "perr_line = np.sqrt(np.diag(cov_line))#誤差抽出\n",
        "#強度測定\n",
        "alpha_calib =np.genfromtxt(basePath+calib_file, skip_footer=6)\n",
        "Tcalib=pathToTime(basePath+calib_file)\n",
        "dy=np.where(alpha_calib > 0, np.sqrt(alpha_calib), 1.0)#誤差は統計誤差の√nのみ,nが0なら0\n",
        "par_calib, cov_calib = curve_fit(sig, x, alpha_calib, p0=(100, 800, 25), sigma=dy)#適切な初期値を与えてフィッティング\n",
        "perr_calib = np.sqrt(np.diag(cov_calib))#分散共分散行列の対角成分取り出し=分散の取り出し\n",
        "scaling=par_line[0]*par_calib[1] + par_line[1]\n",
        "par_line, cov_line = curve_fit(lin, ch, hight/scaling*4.5, sigma=dch)#f(ch+/-dch)=Eを直線(lin)で再フィッティング\n",
        "perr_line = np.sqrt(np.diag(cov_line))#誤差抽出\n",
        "#Alに関する変換\n",
        "dy=np.where(Aldeg0 > 0, np.sqrt(Aldeg0), 1.0)\n",
        "par_Al, cov_Al = curve_fit(sig, x, Aldeg0, p0=(np.max(Aldeg0), np.argmax(Aldeg0), 30), sigma=dy)\n",
        "perr_Al = np.sqrt(np.diag(cov_Al))\n",
        "EAlreco=lin(par_Al[1],par_line[0],par_line[1])\n",
        "dEAlreco=dlin(par_Al[1],par_line[0],par_line[1],perr_Al[1],perr_line[0],perr_line[1])\n",
        "#Auに関する変換\n",
        "dy=np.where(Audeg0 > 0, np.sqrt(Audeg0), 1.0)\n",
        "par_Au, cov_Au = curve_fit(sig, x, Audeg0, p0=(np.max(Audeg0), np.argmax(Audeg0), 25), sigma=dy)\n",
        "perr_Au = np.sqrt(np.diag(cov_Au))\n",
        "EAureco=lin(par_Au[1],par_line[0],par_line[1])\n",
        "dEAureco=dlin(par_Au[1],par_line[0],par_line[1],perr_Au[1],perr_line[0],perr_line[1])\n",
        "\n",
        "Ealphatheo=[1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.1, 4.5]#アルファ線のエネルギー\n",
        "EAltheo=[5.017, 6.804, 8.777, 10.944, 13.308, 15.867, 16.402, 18.618]#Al中の飛程\n",
        "EAutheo=[2.699, 3.435, 4.230, 5.086, 6.002, 6.974, 7.175, 8.001]#Au中の飛程\n",
        "par_Al_line, cov_Al_line = curve_fit(lin, Ealphatheo, EAltheo)#アルファ線のエネルギー[MeV]->アルファ線が飛べるAlの厚さ[um]の式をフィッティング\n",
        "perr_Al_line = np.sqrt(np.diag(cov_Al_line))\n",
        "par_Au_line, cov_Au_line = curve_fit(lin, Ealphatheo, EAutheo)#アルファ線のエネルギー[MeV]->アルファ線が飛べるAlの厚さ[um]の式をフィッティング\n",
        "perr_Au_line = np.sqrt(np.diag(cov_Au_line))\n",
        "RAl=lin(EAlreco,par_Al_line[0],par_Al_line[1])#測定された、残りのエネルギーで飛べるAlの厚さ\n",
        "dRAl=dlin(EAlreco,par_Al_line[0],par_Al_line[1],dEAlreco,perr_Al_line[0],perr_Al_line[1])#その誤差\n",
        "dxAl=18.618-RAl#アルファ線が飛んできたAlの厚さ\n",
        "RAu=lin(EAureco,par_Au_line[0],par_Au_line[1])\n",
        "dRAu=dlin(EAureco,par_Au_line[0],par_Au_line[1],dEAureco,perr_Au_line[0],perr_Au_line[1])\n",
        "dxAu=8.001-RAu\n",
        "\n",
        "\n",
        "\n",
        "#計算\n",
        "dr2=6/2 #mm センサー手前のウィンドウ幅\n",
        "S2=np.pi*dr2**2 #センサー手前のウィンドウ面積\n",
        "L=130 #mm 線源からセンサーまでの距離\n",
        "dOmega_RtoS=S2/L**2 #線源からセンサーまでの見込み角\n",
        "dr1=6/2 #mm ターゲット手前のウィンドウ幅\n",
        "S1=np.pi*dr1**2 #センサー手前のウィンドウ面積\n",
        "L1=58.3 #mm 線源からターゲット手前のウィンドウまでの距離\n",
        "dOmega_RtoT=S1/L1**2 #線源からターゲットの見込み角\n",
        "#オプション課題：ターゲット手前のウィンドウの傾きを考慮するとどうなるか検討する\n",
        "L3=60 #mm ターゲットから線源までの距離\n",
        "dOmega_TtoS=S2/L3**2 #ターゲットから線源までの見込み角\n",
        "#強度測定\n",
        "Ncalib=np.sum(alpha_calib)#キャリブレーションのデータ測定で得られたイベント数を全て足す\n",
        "B0=Ncalib/Tcalib*4*np.pi/dOmega_RtoS#線源強度\n",
        "dB0=np.sqrt(Ncalib)/Tcalib*4*np.pi/dOmega_RtoS#統計誤差\n",
        "B=B0*dOmega_RtoT/4/np.pi\n",
        "dB=dB0*dOmega_RtoT/4/np.pi\n",
        "NA=6.02e23\n",
        "Al_weight=26.98\n",
        "Au_weight=196.97\n",
        "NAl=dxAl*1e-4*2.69*NA/Al_weight #dxAl[cm]*2.69[g/cm^3]*NA[count/mol]/weight[g/mol]\n",
        "dNAl=dRAl*1e-4*2.69*NA/Al_weight\n",
        "NAu=dxAu*1e-4*19.3*NA/Au_weight\n",
        "dNAu=dRAu*1e-4*19.3*NA/Au_weight\n",
        "z = 2  # alpha は4He 2+\n",
        "ZAl = 13  # Alの陽子数は13\n",
        "ZAu = 79  # Auの陽子数は79\n",
        "hbarc = 197.3\n",
        "alpha = 1/137.\n",
        "e2 = hbarc*alpha\n",
        "E = 4.5\n",
        "AAl = (z*ZAl*e2/4/E)**2\n",
        "dsigmadOmegaAl=AAl*(np.sin(np.radians(theta)/2))**-4\n",
        "AAu = (z*ZAu*e2/4/E)**2\n",
        "dsigmadOmegaAu=AAu*(np.sin(np.radians(theta)/2))**-4\n",
        "N_expectedAl=B*tmes*NAl*1e-26*dsigmadOmegaAl*dOmega_TtoS\n",
        "dN_expectedAl=B*tmes*NAl*1e-26*dsigmadOmegaAl*dOmega_TtoS*np.sqrt((dB/B)**2+(1/np.sqrt(NAl)**2)+(dNAl/NAl)**2)\n",
        "N_expectedAu=B*tmes*NAu*1e-26*dsigmadOmegaAu*dOmega_TtoS\n",
        "dN_expectedAu=B*tmes*NAu*1e-26*dsigmadOmegaAu*dOmega_TtoS*np.sqrt((dB/B)**2+(1/np.sqrt(NAu)**2)+(dNAu/NAu)**2)\n",
        "\n",
        "\n",
        "\n",
        "print(\"ターゲットに入射する信号強度={:6.1f} +/- {:6.1f} [Bq]\".format(B,dB))\n",
        "print(\"ターゲットから線源までの見込み角={:10.3e} [sr]\".format(dOmega_TtoS))\n",
        "print(\"Al厚さdx={:10.2f} +/- {:10.2f} [um]\".format(dxAl,dRAl))\n",
        "print(\"Au厚さdx={:10.2f} +/- {:10.2f} [um]\".format(dxAu,dRAu))\n",
        "print(\"キャリブレーションを行った時間={:4.0f}[sec]\".format(Tcalib))\n",
        "print(\"推定測定回数(Al)={:10.1e}+/-{:10.1e}\".format(N_expectedAl,dN_expectedAl))\n",
        "print(\"推定測定回数(Au)={:10.1e}+/-{:10.1e}\".format(N_expectedAu,dN_expectedAu))"
      ],
      "metadata": {
        "id": "TlfYFq3kI8GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "信号事象の測定からはどのような結果が得られたでしょうか？3.0.4.を実行すると簡単に確認できます。"
      ],
      "metadata": {
        "id": "iyFqs3HNaAXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.0.4. 観測結果読み込み\n",
        "#散乱測定ファイル、ファイル名と測定角度を任意の回数入れる\n",
        "Al_file_list=[]\n",
        "Al_file_list.append(['300sec20degAl.csv',20])\n",
        "Al_file_list.append(['60sec10degAl.csv',10])\n",
        "Au_file_list=[]\n",
        "Au_file_list.append(['Au50deg68h.csv',50])\n",
        "\n",
        "\n",
        "theta_Al=[]\n",
        "dsdW_Al=[]\n",
        "fig_list=[]\n",
        "for file_i in Al_file_list :\n",
        "  Al_file=np.genfromtxt(basePath+file_i[0], skip_footer=6)\n",
        "  theta_Al.append(file_i[1])\n",
        "  Nsig=np.sum(Al_file)\n",
        "  tmes=pathToTime(basePath+file_i[0])\n",
        "  dsdW_Al.append(Nsig/(B*tmes*NAl*1e-26*dOmega_TtoS))\n",
        "  print(\"測定数　{:.2f} 測定時間{:.2f}\".format(Nsig,tmes))\n",
        "\n",
        "  fig_i = plt.figure(figsize=(6, 6))\n",
        "  fig_list=np.append(fig_list,fig_i)\n",
        "  ax = fig_list[-1].add_subplot(111)\n",
        "  _ = ax.hist(x, bins=1024, weights=Al_file, range=(0, 1024), alpha=0.5, label='Al data {:.0f} taking in {:.0f} sec'.format(file_i[1],tmes))\n",
        "  plt.xlabel('MCA channel [ch]', fontsize=18, fontfamily='serif')#x軸の名前\n",
        "  plt.ylabel('Event count', fontsize=18, fontfamily='serif')#y軸の名前\n",
        "  plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "theta_Au=[]\n",
        "dsdW_Au=[]\n",
        "for file_i in Au_file_list :\n",
        "  Au_file=np.genfromtxt(basePath+file_i[0], skip_footer=6)\n",
        "  theta_Au.append(file_i[1])\n",
        "  Nsig=np.sum(Au_file)\n",
        "  tmes=pathToTime(basePath+file_i[0])\n",
        "  dsdW_Au.append(Nsig/(B*tmes*NAu*1e-26*dOmega_TtoS))\n",
        "  print(\"測定数　{:.2f} 測定時間{:.2f}\".format(Nsig,tmes))\n",
        "\n",
        "  fig_i = plt.figure(figsize=(6, 6))\n",
        "  fig_list=np.append(fig_list,fig_i)\n",
        "  ax = fig_list[-1].add_subplot(111)\n",
        "  _ = ax.hist(x, bins=1024, weights=Au_file, range=(0, 1024), alpha=0.5, label='Au data {:.0f} taking in {:.0f} sec'.format(file_i[1],tmes))\n",
        "  plt.xlabel('MCA channel [ch]', fontsize=18, fontfamily='serif')#x軸の名前\n",
        "  plt.ylabel('Event count', fontsize=18, fontfamily='serif')#y軸の名前\n",
        "  plt.legend(loc='upper right')\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = fig.add_subplot(111)\n",
        "theta_x=np.arange(1,90)#プロットするx軸のbinを設定\n",
        "fAl=AAl*(np.sin(np.radians(theta_x)/2))**-4\n",
        "fAu=AAu*(np.sin(np.radians(theta_x)/2))**-4\n",
        "ax.plot(theta_x, fAl, 'b-',label='Al theory')\n",
        "ax.plot(theta_x, fAu, 'r-',label='Au theory')\n",
        "plt.yscale('log')  # ログスケール\n",
        "ax.set_xlabel(r'$\\theta$ (deg.)')\n",
        "ax.set_ylabel(r'$d\\sigma/d\\Omega$ (fm$^2$)')\n",
        "plt.errorbar(theta_Al,dsdW_Al,fmt=\"o\",color=\"b\",label='Al data')#測定値Al\n",
        "plt.errorbar(theta_Au,dsdW_Au,fmt=\"o\",color=\"r\",label='Au data')#測定値Au\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "K1pfI7rsVAOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1. 背景事象推定"
      ],
      "metadata": {
        "id": "2r8s59mQaGPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "有意性の推定を行うためには、背景事象の推定と誤差の見積もりが不可欠です。まずは背景事象の推定を行います。\n",
        "\n",
        "今回の実験では、背景事象としては次のようなものが考えられます\n",
        "\n",
        "1.   線源とは無関係な自然放射線の入射\n",
        "2.   薄膜を通過せずに直接センサーへ入射する粒子\n",
        "3.   薄膜以外の位置で散乱されてセンサーに入射する粒子\n",
        "\n",
        "式からもわかるように、背景事象をいかに減らせるか、背景事象を信号事象からどれだけ正確に取り除けるか、そのうえで信号事象をいかに稼げるかが課題となります。\n",
        "\n",
        "1.に関しては、先行実験で線源のない状態でt=4515秒の測定を行い$N_{obs}$=1イベントが観測されました。統計数が少ないためポアソン分布\n",
        "$$\n",
        "P(N|\\lambda, t)=\\frac{e^{-\\lambda t}(\\lambda t)^N}{N!}\n",
        "$$\n",
        "を仮定します。ここでは１度しか計測していないので、λに関して保守的な見積もりをします。具体的には、観測数が$N_{obs}$かそれ以下である確率が5%となるような最大のλを採用します。\n",
        "\n",
        "$$\n",
        "\\Sigma_{N=0}^{N_{obs}}P(N|\\lambda, t)=0.05\n",
        "$$\n",
        "\n",
        "3.1.1.を実行して、$\\lambda$を求めましょう。より長時間の測定を行えば、保守的な推測でも$\\lambda$の値は小さくなります。"
      ],
      "metadata": {
        "id": "f1O6tL6mSdwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.1.1. 自然放射線量の推定\n",
        "def N_to_lambda(N,p):\n",
        "    bnds=((N,N),(0,None))\n",
        "    func=lambda x: (poisson.cdf(x[0],x[1])-p)**2\n",
        "    res=minimize(func,(N,N*2),bounds=bnds)\n",
        "    for i in range(0,N+1):\n",
        "      print(\"{:2d} {:.2e}\".format(i,100*poisson.pmf(i,res.x[1])))\n",
        "    return res.x[1]\n",
        "\n",
        "Nobs=1\n",
        "t=4515\n",
        "lamb=N_to_lambda(Nobs,0.05)\n",
        "print(\"推定されたlambda*t={:.2f}->lambda={:.2e}\".format(lamb,lamb/t))\n",
        "print(\"推定された背景事象数={:.2e}\".format(lamb*tmes/t))\n"
      ],
      "metadata": {
        "id": "wn6Xn8luaZbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.及び3.の背景事象に関しては、ターゲット前後に障壁を作り信号事象を除去することで直接測定が可能です。背景事象の信号の形は実験セットアップにより大きく異なります。測定を行ったら、まずは3.1.2.で分布を比較しましょう。"
      ],
      "metadata": {
        "id": "DPybH4_EGm97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.1.2. 線源由来背景事象の測定\n",
        "#背景事象測定ファイル、適宜書き換えること\n",
        "BG_file='BGlong.csv'\n",
        "\n",
        "x=np.arange(0,1024)#x軸\n",
        "bgy = np.genfromtxt(basePath+BG_file, skip_footer=6)\n",
        "\n",
        "sigtemp=np.genfromtxt(basePath+Au_file_list[0][0], skip_footer=6)\n",
        "\n",
        "#必要に応じてrebin,最後の数字がまとめるbinの数\n",
        "Nrebin=20\n",
        "xtemp=x\n",
        "xsig=x\n",
        "bgtemp=bgy\n",
        "x,bgy=rebin(x,bgy,Nrebin)\n",
        "xsig,sigtemp=rebin(xsig,sigtemp,Nrebin)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = fig.add_subplot(111)\n",
        "plt.xlabel('MCA channel [ch]', fontsize=18, fontfamily='serif')#x軸の名前\n",
        "plt.ylabel('Event count', fontsize=18, fontfamily='serif')#y軸の名前\n",
        "plt.yscale('log')  # ログスケール\n",
        "Tbg=pathToTime(basePath+BG_file)#sec, 背景事象の測定時間に書き換える\n",
        "_ = ax.hist(x, bins=len(x)-1, weights=bgy, range=(0, 1024), alpha=0.5, label='BG data taking in {:.0f} sec'.format(Tbg))\n",
        "_ = ax.hist(x, bins=len(x)-1, weights=sigtemp, range=(0, 1024), alpha=0.5, label='Sig data taking in {:.0f} sec'.format(pathToTime(basePath+Au_file_list[0][0])))\n",
        "Nbg=np.sum(bgy)#背景事象測定で得られたイベント数を全て足す\n",
        "plt.legend(loc='upper right')\n",
        "print(\"{:.0f}secで測定した背景事象数{:.2e} -> {:.0f}secに予想される大まかな信号に混じる推定背景事象数{:.2e}\".format(Tbg,Nbg,tmes,Nbg/Tbg*tmes))\n",
        "x=xtemp#rebin前のx軸に戻す\n",
        "bgy=bgtemp\n",
        "sigPlot=np.genfromtxt(basePath+Au_file_list[0][0], skip_footer=6)\n",
        "\n"
      ],
      "metadata": {
        "id": "T5sSM0brHdlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "分布の重なり具合に応じて状況に応じた評価が必要です。\n",
        "- チャンネルを制限すれば信号数を減らさずに背景事象数が減らせるのであれば、事象をカウントするチャンネル数を制限しましょう。\n",
        "- 分布は重なってしまっているが、形が異なる場合(exponentialなど)の場合は、背景事象+信号事象の関数でフィッティングすることで信号事象のみ抽出することができます。\n",
        "- 分布が重なってしまっており、かつ形も同じ場合は、直接的な推定は困難です。統計数を稼ぐなどの工夫が必要です。\n",
        "- 背景事象数が十分少ないのであれば、3.1.1.と同様の手法で推定しても良いでしょう。\n",
        "\n",
        "3.1.3.では、仮の推定のセルを用意しています。測定されたデータに応じて書き換えやセルの追加をして実行してください。"
      ],
      "metadata": {
        "id": "7_3rjiDnso8n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeSzmxDRsmSb"
      },
      "outputs": [],
      "source": [
        "# @title 3.1.3. 線源由来背景事象の測定\n",
        "#必要に応じてrebin,最後の数字がまとめるbinの数\n",
        "Nrebin=10\n",
        "xtemp=x\n",
        "xsig=x\n",
        "bgtemp=bgy\n",
        "sigtemp=sigPlot\n",
        "x,bgy=rebin(x,bgy,Nrebin)\n",
        "xsig,sigPlot=rebin(xsig,sigPlot,Nrebin)\n",
        "\n",
        "#プロット作成\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "ax = fig.add_subplot(111)\n",
        "_ = ax.hist(x, bins=len(x)-1, weights=bgy, range=(0, 1024), label='BG')#背景事象のヒストグラムを作成\n",
        "fig2 = plt.figure(figsize=(6, 4))\n",
        "ax2 = fig2.add_subplot(111)\n",
        "_ = ax2.hist(x, bins=len(x)-1, weights=sigPlot, range=(0, 1024), label='sig')#信号事象のヒストグラムを作成\n",
        "\n",
        "#フィット範囲定義,要調整\n",
        "peakMin=400\n",
        "peakMax=600\n",
        "#背景事象をフィット\n",
        "xexp=x[x<peakMin]\n",
        "yexp=bgy[x<peakMin]\n",
        "dyexp=np.where(yexp > 0, np.sqrt(yexp), 1.0)\n",
        "parBGexp,covBGexp= curve_fit(bg, xexp, yexp, p0=(yexp[0], 50), sigma=dyexp)\n",
        "perrBGexp = np.sqrt(np.diag(covBGexp))\n",
        "mat = np.vstack((parBGexp,perrBGexp)).T\n",
        "df = pd.DataFrame(mat,index=(\"Constant\", \"Sigma\"), columns=(\"Estimate\", \"Std. error\"))\n",
        "print(df)\n",
        "y = bg(x, *parBGexp)\n",
        "_ = ax.plot(x, y, 'b-', label='fitBG')\n",
        "\n",
        "#信号事象のピーク成分をフィット\n",
        "xpeak=x[(peakMin<x)&(x<peakMax)]\n",
        "ypeak=sigPlot[(peakMin<x)&(x<peakMax)]-bgy[(peakMin<x)&(x<peakMax)]/Tbg*tmes#時間でスケールした背景事象成分を取り除く\n",
        "dypeak=np.where(ypeak > 0, np.sqrt(ypeak), 1.0)\n",
        "parSIGpeak,covSIGpeak= curve_fit(sig, xpeak, ypeak, p0=(np.max(ypeak), np.argmax(ypeak), 100), sigma=dypeak)\n",
        "perrSIGpeak = np.sqrt(np.diag(covSIGpeak))\n",
        "mat = np.vstack((parSIGpeak,perrSIGpeak)).T\n",
        "df = pd.DataFrame(mat,index=(\"Constant\", \"Mean\", \"Sigma\"), columns=(\"Estimate\", \"Std. error\"))\n",
        "print(df)\n",
        "y = sig(x, *parSIGpeak)\n",
        "_ = ax2.plot(x, y, 'r-', label='fitSIGpeak')\n",
        "\n",
        "\n",
        "#信号事象全体をフィット\n",
        "dy=np.where(bgy > 0, np.sqrt(sigPlot), 1.0)\n",
        "parAll,covAll= curve_fit(sigFull, x, sigPlot, p0=(parSIGpeak[0],parSIGpeak[1],parSIGpeak[2],parBGexp[0],parBGexp[1]), sigma=dy)#上記フィットで得られた値を初期値として使う\n",
        "perrAll = np.sqrt(np.diag(covAll))\n",
        "mat = np.vstack((parAll,perrAll)).T\n",
        "df = pd.DataFrame(mat,index=(\"ConstantGaus\", \"Mean\", \"SigmaGaus\",\"ConstantExp\",\"SigmaExp\"), columns=(\"Estimate\", \"Std. error\"))\n",
        "print(df)\n",
        "y = sigFull(x, *parAll)\n",
        "_ = ax2.plot(x, y, 'g-', label='fitAll')\n",
        "\n",
        "#感度推定\n",
        "peakMin=parAll[1]-3*parAll[2]#ピーク位置から+-3σ分だけカウント=信号事象の99.7%\n",
        "peakMax=parAll[1]+3*parAll[2]\n",
        "n=np.sum(sigPlot[(peakMin<x)&(x<peakMax)])\n",
        "dn=np.sqrt(n)\n",
        "print(\"from {:.2f} to {:.2f}\".format(peakMin,peakMax))\n",
        "b,db=integrate.quad(lambda x: bg(x,parBGexp[0],parBGexp[1]), peakMin, peakMax)#背景事象成分を上記範囲で積分\n",
        "print(\"背景事象数 {:.2e} +/- {:.2e}\".format(b,db))\n",
        "sigma=np.sqrt(dn**2+db**2+b)#全測定事象の統計誤差、背景事象の推定誤差、背景事象の統計誤差を考慮\n",
        "print(\"背景事象数 {:.2e} +/- {:.2e} と推測されるとき、{:.1e}回より大きく予想が外れる確率{:.2f}σ={:.2e}%\".format(b,sigma,n,significance(n,b,sigma),prob(significance(n,b,sigma))*100))\n",
        "plt.legend(loc='upper right')\n",
        "x=xtemp#rebin前のx軸に戻す\n",
        "bgy=bgtemp\n",
        "sigPlot=sigtemp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2. 誤差推定"
      ],
      "metadata": {
        "id": "DKIzjbQrcPNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "これまでは各種測定事象数に依存する統計誤差とその伝搬のみを誤差として取り扱ってきました。しかし、実際には測定装置や測定手法に依存する誤差も考慮する必要があります。背景事象の推定においては、推定手法に依存した誤差がないか検討しましょう。\n",
        "\n",
        "信号事象においては、理論的な推定数に対し実際に観測された事象数に大きな乖離が見られたのではないでしょうか。これに関しても、誤差を議論することで理解することができます。3.2.1.をヒントとして用いて、誤差の原因について議論しましょう。"
      ],
      "metadata": {
        "id": "YyTZy0s8cR9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.2.1. 角度議論用ツール\n",
        "L1=58.3#mm\n",
        "L2=11.7#mm\n",
        "L3=60#mm\n",
        "flag=1\n",
        "alpha=-1*flag#cos(agnle) on target\n",
        "beta=1*flag#cos(angle) on sensor\n",
        "gamma=1*flag#cos(angle) on radiation source\n",
        "ds1=3#mm, window size behind the target\n",
        "ds2=3#mm, window size behind the sensor\n",
        "dsi=5#mm, window size of radiation source\n",
        "\n",
        "#theta_orig=theta\n",
        "theta_orig=15\n",
        "theta_orig=np.radians(theta_orig)\n",
        "\n",
        "vL12=np.array([0,0,L1+L2])\n",
        "vdL12=np.array([alpha*np.cos(np.pi/6),0,alpha*np.sin(np.pi/6)])\n",
        "vdL12*=ds1*(L1+L2)/L1\n",
        "vdLi=np.array([dsi*gamma,0,0])\n",
        "vLI=vL12+vdL12-vdLi\n",
        "\n",
        "vL3=np.array([-L3*np.sin(theta_orig),0,L3*np.cos(theta_orig)])\n",
        "vdL3=np.array([ds2*beta*np.sin(theta_orig),0,ds2*beta*np.cos(theta_orig)])\n",
        "vLO=vL3+vdL3-vdL12\n",
        "print(\"流入ベクトル角度{:.3f} 散乱ベクトル角度{:.3f} 散乱しない粒子の流入が可能か{:b}\".format(np.degrees(np.arctan(vLI[0]/vLI[2])),np.degrees(np.arctan(vLO[0]/vLO[2])),np.degrees(np.arctan(vLI[0]/vLI[2]))<np.degrees(np.arctan(vLO[0]/vLO[2]))))\n",
        "\n",
        "thetap=np.arccos(np.dot(vLI,vLO)/np.sqrt(np.dot(vLI,vLI)*np.dot(vLO,vLO)))\n",
        "print(\"最大ずれ角度{:.3f}\".format(np.degrees(thetap)))"
      ],
      "metadata": {
        "id": "tBkxUhp26r35"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}